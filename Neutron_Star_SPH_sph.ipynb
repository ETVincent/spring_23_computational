{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "300306e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import gamma\n",
    "import time\n",
    "import math\n",
    "import matplotlib as mp\n",
    "import scipy as sp\n",
    "import pylab as py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55451471",
   "metadata": {},
   "source": [
    "# SPH Implementation\n",
    "### The Gaussian Smoothing function is used to smooth out the point values, extrapolating them to other positions.\n",
    " Given the distribution of particles, we can reconstruct the density at any location using the smoothing kernels. For example, the density at each SPH particle location is a sum over all the particles with weighting set by the distances between particles and the smoothing kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa6fd363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cubic_spline_kernel(x,y,z,h):\n",
    "    sigma = 10/(7*np.pi*h**2)\n",
    "    r = np.sqrt(x**2 + y**2 + z**2)\n",
    "    if r <= 1:\n",
    "        return -1.5*r + 0.75*r**2*sigma\n",
    "    elif r<=2:\n",
    "        return -0.75*sigma*(2-r)**2\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def W(x,y,z,h, tag = \"gaussian\"):\n",
    "    \"\"\" Defined Smoothing kernel (3D).\n",
    "    (x is a vector/matrix of x positions, y is a vector/matrix of y positions. \n",
    "    z = vector/matrix of z positions, h = smoothing length, w = evaluated smoothing function.\n",
    "    Implemented Gaussian, Wendland C2 and Wendland C4 smoothing kernels as recommended by (Rosswog, 2015).\n",
    "    \"\"\"\n",
    "    r = np.sqrt(x**2 + y**2 + z**2) \n",
    "    ### ========= Gaussian kernel\n",
    "    if tag == \"gaussian\":\n",
    "        w = (1.0 / (h*np.sqrt(np.pi)))**3 * np.exp( -r**2 / h**2) # return w  \n",
    "    ### ========= WENDLAN KERNEL (ROSSWOG, 2015) ========= ###    # bb\n",
    "    elif tag == \"wendland_2\": # Wendland C2\n",
    "        alpha = 21/(16*np.pi*h**3)\n",
    "        if r <= 2:\n",
    "            w = alpha*(1-r/2)**4*(2*r+1)\n",
    "        else:\n",
    "            w = 0         \n",
    "    elif tag == \"wendland_4\": # Wendland C4\n",
    "        alpha = 495/(256*np.pi*h**3)\n",
    "        if r <= 2:\n",
    "            w = alpha*(1-r/2)**6*(35/12*r**2 + 3*r + 1)\n",
    "        else:\n",
    "            w = 0\n",
    "    elif tag == \"cubic_spline\":\n",
    "        return grad_cubic_spline_kernel(x,y,z,h)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Trying to implement Unknown Kernel.\")\n",
    "    return w\n",
    "\n",
    "def gradW(x,y,z,h,tag = \"gaussian\"):\n",
    "    \"\"\" Gradient of smoothing kernel. We can reconstruct the density at any location using the smoothing kernels.\n",
    "    (x is a vector/matrix of x positions, y is a vector/matrix of y positions, z is a vector/matrix of z positions, h is the smoothing length, wx, wy, wz  is the evaluated gradient)\"\"\"\n",
    "    r = np.sqrt(x**2 + y**2 + z**2)  \n",
    "    if tag == \"gaussian\":\n",
    "        n = -2 * np.exp( -r**2 / h**2) / h**5 / (np.pi)**(3/2)\n",
    "    ### ========= WENDLAN KERNEL (ROSSWOG, 2015) ========= ###  \n",
    "        # Gradient of WendlandQuintic kernel(C2) for 3D.         # https://pysph.readthedocs.io/en/latest/reference/kernels.html\n",
    "    elif tag == \"wendland_2\":\n",
    "        alpha = 7/(4*np.pi*h**2) ## Take derivative wrt r\n",
    "        r[r>2] = 0 # set all the values in r greater than 2 to 2.\n",
    "        n = alpha*(-2*(1-r/2)**3*(2*r+1) +2*(1-r/2)**4)\n",
    "        # Gradient of WendlandQuintic kernel(C4) for 3D.          # https://pysph.readthedocs.io/en/latest/reference/kernels.html\n",
    "    elif tag == \"wendland_4\": # Wendland C4\n",
    "        r[r>2] = 0\n",
    "        alpha = 495/(256*np.pi*h**3) ## Take derivative wrt r\n",
    "        n = alpha*-2.5*(1-r/2)**5*(35/12*r**2 + 3*r + 1) + (1-r/2)**6*(35/12*r +3) ## Take derivative wrt r\n",
    "    elif tag == \"cubic_spline\":\n",
    "        return grad_cubic_spline_kernel(x,y,z,h)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Trying to use the gradient of an Unknown Kernel.\")\n",
    "    return n*x, n*y, n*z  # (gradient in the x, y, and z directions)\n",
    "    \n",
    "def getPairwiseSeparations(ri, rj):\n",
    "    \"\"\" Just finds Cartesian Pairwise Separations between 2 points. \n",
    "    ri is an M x 3 matrix of positions, \n",
    "    rj    is an N x 3 matrix of positions \n",
    "    returns dx, dy, dz   are M x N matrices of separations. \"\"\"\n",
    "    M = ri.shape[0]\n",
    "    N = rj.shape[0]\n",
    "    rix = ri[:,0].reshape((M,1)) # positions ri = (x,y,z)\n",
    "    riy = ri[:,1].reshape((M,1))\n",
    "    riz = ri[:,2].reshape((M,1))\n",
    "    rjx = rj[:,0].reshape((N,1)) # other set of points positions rj = (x,y,z)\n",
    "    rjy = rj[:,1].reshape((N,1))\n",
    "    rjz = rj[:,2].reshape((N,1))\n",
    "    return rix - rjx.T , riy - rjy.T, riz - rjz.T # (dx, dy, dz) # return matrices that store all pairwise particle separations: r_i - r_j\n",
    "\n",
    "def getDensity(r, pos, m, h ):\n",
    "    \"\"\" Reconstruct the density at any location based on the sph points.\n",
    "            r     is an M x 3 matrix of sampling locations\n",
    "            pos   is an N x 3 matrix of SPH particle positions\n",
    "          \n",
    "          dx, dy, dz are all M x N matrices. (Seperations). \n",
    "          - Sum over all particle interactions with the points to get the density at the locations in r.\n",
    "          \n",
    "          m = particle mass, h = smoothing length \"\"\"\n",
    "    M = r.shape[0]\n",
    "    dx, dy, dz = getPairwiseSeparations( r, pos );\n",
    "    rho = np.sum( m * W(dx, dy, dz, h), 1 ).reshape((M,1)) # (56)\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79e53ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.34081344e-06]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r =  np.asarray([[0.8607446,0.8607446,0.8607446]])\n",
    "pos =  np.asarray([[0.860744,0,1]])\n",
    "m =  0.01\n",
    "h = np.asarray([[11]])\n",
    "getDensity(r, pos, m, h )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0f32ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.44860231]\n",
      "(array([-1.16007529]), array([-1.16007529]), array([-1.16007529]))\n",
      "[-8.96911677]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Wendland kernel\n",
    "h = 0.1\n",
    "x = np.asarray([1])\n",
    "y = np.asarray([1])\n",
    "z = np.asarray([1])\n",
    "\n",
    "out2 = gradW(x,y,z,h, tag = \"wendland_2\")\n",
    "\n",
    "def w(q,h):\n",
    "    # dim 3\n",
    "    a_d = 21/(16*np.pi*h**3)\n",
    "    return a_d*(1-q/2)**4*(2*q + 1)\n",
    "\n",
    "def dw(x,h):\n",
    "    a_d = 7/(4*np.pi*h**3)\n",
    "    return a_d*-2*(1-x/2)**3*(2*x+1) + 2*(1-x/2)**4\n",
    "\n",
    "r = np.sqrt(x**2+y**2+z**2)\n",
    "out1 = dw(r,h)\n",
    "print(grad_cubic_spline_kernel(x,y,z,h))\n",
    "print(out2)\n",
    "print(out1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a48c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vanilla_dv_dt1(m, M, P, rho,v,dWx,dWy,dWz,nu=0):\n",
    "    \"\"\" Reconstruct dV/dt at any sph point.\n",
    "             Vanilla Ice formulation, see Rosswog et. al (2015)\n",
    "\n",
    "          dx, dy, dz are all M x N matrices. (Seperations). \n",
    "          - Sum over all particle interactions \n",
    "          \n",
    "          m = particle mass, h = smoothing length \"\"\"\n",
    "    ##### Fix this part #####\n",
    "    print(\"\\n\\n Inside vanilladvdt\\n\\n\")\n",
    "    Pa=P\n",
    "    Pb = P\n",
    "    rhoa = rho\n",
    "    rhob = rho\n",
    "    ########################\n",
    "    dvdtx = np.sum(-m*(Pa/rhoa**2 + Pb/rhob**2)*dWx + nu*dWx, 1 ).reshape((M,1)) # pretty sure this is right. \n",
    "    dvdty = np.sum(-m*(Pa/rhoa**2 + Pb/rhob**2)*dWy + nu*dWx, 1 ).reshape((M,1))\n",
    "    dvdtz = np.sum(-m*(Pa/rhoa**2 + Pb/rhob**2)*dWz + nu*dWx, 1 ).reshape((M,1))\n",
    "    print(\"Vanilla: dvdt exmaple: \", str(dvdtx[0]))\n",
    "    return dvdtx,dvdty,dvdtz\n",
    "\n",
    "def RS_1(m, M, P, rho,v,dWx,dWy,dWz,nu=0):\n",
    "    print(\"\\n\\n Inside RS1\\n\\n\")\n",
    "    \"\"\" Reconstruct dV/dt at any sph point.\n",
    "             Vanilla Ice formulation, see Rosswog et. al (2015)\n",
    "\n",
    "          dx, dy, dz are all M x N matrices. (Seperations). \n",
    "          - Sum over all particle interactions \n",
    "          \n",
    "          m = particle mass, h = smoothing length \"\"\"\n",
    "    v_x,v_y,v_z = getPairwiseSeparations(v,v)\n",
    "    print(\"RS1: Pairwise velocity separation exmaple: \", str(v_x[0]))\n",
    "    vx_sum = v_x.sum(axis=0)\n",
    "    print(\"VX_SUM: \", str(vx_sum))\n",
    "    vy_sum = v_y.sum(axis=0)\n",
    "    vz_sum = v_z.sum(axis=0)\n",
    "    ########################\n",
    "    dvdtx = np.sum(-m*(P/rho**2 + 0.5*nu)*v_x*dWx, 1 ).reshape((M,1))\n",
    "    dvdty = np.sum(-m*(P/rho**2 + 0.5*nu)*v_y*dWy, 1 ).reshape((M,1))\n",
    "    dvdtz = np.sum(-m*(P/rho**2  + 0.5*nu)*v_z*dWz, 1 ).reshape((M,1))\n",
    "    return dvdtx,dvdty,dvdtz\n",
    "\n",
    "def RS_2(gamma, rho, m,v, dWx,dWy,dWz,nu=0):\n",
    "    \"\"\" Reconstruct dV/dt at any sph point.\n",
    "             Vanilla Ice formulation, see Rosswog et. al (2015)\n",
    "\n",
    "          dx, dy, dz are all M x N matrices. (Seperations). \n",
    "          - Sum over all particle interactions \n",
    "          \n",
    "    m = particle mass, h = smoothing length \"\"\"\n",
    "    v_x, v_y, v_z = getPairwiseSeparations(v,v)\n",
    "    v_ = np.sqrt(v_x**2 + v_y**2 + v_z**2)\n",
    "    c = (gamma-1)*(1/rho**(gamma-1)) # constant, same dimensions as rho\n",
    "    ########################\n",
    "    dAdtx = np.sum(-m*(P/rho**2 + 0.5*nu)*v_*dWx, 1 ).reshape((M,1))\n",
    "    dAdty = np.sum(-m*(P/rho**2 + 0.5*nu)*v_*dWy, 1 ).reshape((M,1))\n",
    "    dAdtz = np.sum(-m*(P/rho**2  + 0.5*nu)*v_*dWz, 1 ).reshape((M,1))\n",
    "    return dvdtx,dvdty,dvdtz\n",
    "\n",
    "class discrete_lagrange():\n",
    "    \"\"\" Lagrangian formulation \"\"\"\n",
    "    def __init__(self, tag = \"vanilla\"): \n",
    "        if tag == \"vanilla\":\n",
    "            self.info = \"Vanilla Ice discitization of lagrange formulations for conservation for an ideal fluid. Outlined in (10.1007/lrca-2015-1).\"\n",
    "            self.dvdt = lambda m, M, P, rho,v,dWx,dWy,dWz,nu : Vanilla_dv_dt1(m, M, P, rho,v,dWx,dWy,dWz,nu) \n",
    "        elif tag == \"RS91\":\n",
    "            self.info = \"Uses dudt from Rasio & Shaprio (1991).\"\n",
    "            self.dvdt = lambda m, M, P, rho,v,dWx,dWy,dWz,nu : RS_1(m, M, P, rho,v,dWx,dWy,dWz,nu) \n",
    "        elif tag == \"RS92\":\n",
    "            self.info = \"Uses dAdt from Rasio & Shaprio (1991).\"\n",
    "            self.dAdt = lambda gamma, rho, m, dWx,dWy,dWz,nu : RS_2(m, M, P, rho,v,dWx,dWy,dWz,nu) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
